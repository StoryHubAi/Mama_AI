# üéôÔ∏è Speech-to-Text Configuration Guide for MAMA-AI

## Overview

MAMA-AI now supports real speech-to-text conversion for voice calls! This enhancement allows users to speak naturally to the AI assistant instead of using only keypad inputs.

## ‚úÖ What's New

### Enhanced Voice Recording Endpoint
- Real speech-to-text processing instead of placeholder text
- Support for multiple speech-to-text providers
- Language-aware conversion (English and Kiswahili)
- Intelligent fallback responses
- Detailed logging for debugging

### New Speech-to-Text Service
- **Multiple Providers**: OpenAI Whisper, Google Speech-to-Text, Azure Speech Services
- **Language Support**: English (US/UK) and Kiswahili (Kenya)
- **Mock Mode**: For testing without API keys
- **Error Handling**: Graceful fallbacks when speech recognition fails

## üîß Configuration Options

### Option 1: OpenAI Whisper (Recommended)
**Pros**: Excellent accuracy, supports many languages, easy to set up
**Cons**: Requires OpenAI API key

```bash
# Add to your .env file
SPEECH_TO_TEXT_PROVIDER=whisper
OPENAI_API_KEY=your_openai_api_key_here
```

**Setup Steps:**
1. Go to https://platform.openai.com/api-keys
2. Create a new API key
3. Add it to your `.env` file as `OPENAI_API_KEY`

### Option 2: Google Speech-to-Text
**Pros**: High accuracy, good Kiswahili support
**Cons**: More complex setup, requires Google Cloud account

```bash
# Add to your .env file
SPEECH_TO_TEXT_PROVIDER=google
GOOGLE_SPEECH_API_KEY=your_google_api_key_here
```

**Setup Steps:**
1. Go to Google Cloud Console
2. Enable Speech-to-Text API
3. Create credentials and get API key
4. Add it to your `.env` file

### Option 3: Azure Speech Services
**Pros**: Enterprise-grade, good performance
**Cons**: Requires Azure account

```bash
# Add to your .env file
SPEECH_TO_TEXT_PROVIDER=azure
AZURE_SPEECH_KEY=your_azure_speech_key
AZURE_SPEECH_REGION=your_azure_region
```

### Option 4: Mock Mode (Testing)
**Pros**: No API keys needed, perfect for testing
**Cons**: Not real speech recognition

```bash
# Add to your .env file (or omit to use default)
SPEECH_TO_TEXT_PROVIDER=mock
```

## üöÄ How It Works

### 1. User Calls Voice Number
- User dials your Africa's Talking voice number
- Hears AI-powered welcome message

### 2. Voice Menu Options
- **DTMF (Keypad)**: Press 1, 2, 3, 4, or 9 for menu navigation
- **Voice Input**: Speak naturally after the beep

### 3. Speech Processing
- Recording sent to speech-to-text service
- Text converted to user's preferred language
- AI processes the spoken question

### 4. AI Response
- AI generates contextual response
- Spoken back to user via text-to-speech
- Option to continue conversation

## üìù Example Voice Interactions

### English Examples:
- *"I need help with my pregnancy"*
- *"I'm feeling some pain in my stomach"*
- *"When is my next appointment?"*
- *"I want to check my pregnancy status"*

### Kiswahili Examples:
- *"Nahitaji msaada na uja uzito wangu"*
- *"Nahisi maumivu katika tumbo langu"*
- *"Ni lini miadi yangu ijayo?"*
- *"Nataka kuangalia hali ya uja uzito wangu"*

## üß™ Testing the Enhancement

### 1. Test Speech-to-Text Service
```bash
cd D:\projects\AT\Mama_AI
python src/services/speech_to_text_service.py
```

### 2. Test Voice Integration
```bash
python test_voice.py
```

### 3. Check Logs
- Watch Flask console for speech-to-text processing logs
- Look for confidence scores and provider information

## üîç Monitoring and Debugging

### Key Log Messages to Watch:
```
Converting speech to text for recording: [URL]
Speech-to-text successful - Text: [transcript], Confidence: [score], Provider: [provider]
STT Note: This is a mock response for testing...
Speech-to-text failed: [error message]
```

### Common Issues and Solutions:

**Issue**: "Speech-to-text failed"
- **Solution**: Check API keys in `.env` file
- **Fallback**: Service automatically uses mock responses

**Issue**: "No recording URL provided"
- **Solution**: Verify Africa's Talking voice settings allow recordings
- **Check**: Voice callback URL is correct

**Issue**: Low confidence scores
- **Solution**: Ask users to speak clearly
- **Tip**: Background noise affects accuracy

## üåç Language Support

### Currently Supported:
- **English (US)**: `en-US`
- **English (UK)**: `en-GB`  
- **Kiswahili (Kenya)**: `sw-KE`

### Language Auto-Detection:
- Based on user's preferred language setting
- Falls back to English if language not detected
- AI responses match user's language preference

## üí° Advanced Features

### 1. Confidence Scoring
- Each speech-to-text result includes confidence score
- Low confidence triggers clarification requests
- Logged for quality monitoring

### 2. Multi-Provider Fallback
- If primary provider fails, automatically tries alternatives
- Mock responses ensure service never completely fails
- Seamless user experience

### 3. Context-Aware Processing
- Speech-to-text considers medical/pregnancy context
- AI responses use conversation history
- Session management for multi-turn conversations

## üîß Environment Variables Reference

```bash
# Speech-to-Text Settings
SPEECH_TO_TEXT_PROVIDER=whisper          # Provider: whisper, google, azure, mock
OPENAI_API_KEY=sk-...                   # OpenAI API key for Whisper
GOOGLE_SPEECH_API_KEY=...               # Google Speech API key
AZURE_SPEECH_KEY=...                    # Azure Speech Services key
AZURE_SPEECH_REGION=eastus              # Azure region

# Voice Settings (existing)
BASE_URL=https://yourdomain.com         # Your public domain
VOICE_PHONE_NUMBER=+254700000000        # Your AT voice number
```

## üéØ Next Steps

### For Production:
1. **Choose a Provider**: Set up API keys for your preferred service
2. **Update Environment**: Add speech-to-text configuration to `.env`
3. **Test Thoroughly**: Use real voice calls to verify accuracy
4. **Monitor Performance**: Check logs for speech recognition quality

### For Development:
1. **Use Mock Mode**: Test without API keys
2. **Implement Custom Prompts**: Enhance AI responses for voice
3. **Add More Languages**: Extend support for local languages
4. **Analytics**: Track speech recognition accuracy and user satisfaction

## üéâ Congratulations!

Your MAMA-AI voice service now includes:
- ‚úÖ Real speech-to-text processing
- ‚úÖ Multiple provider support
- ‚úÖ Language-aware conversion
- ‚úÖ Intelligent fallbacks
- ‚úÖ Enhanced logging and monitoring

Users can now have natural voice conversations with MAMA-AI! üó£Ô∏èü§ñ

---

**Need Help?** Check the logs, test with mock mode first, and verify your API keys are correct.
